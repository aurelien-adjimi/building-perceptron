# building-perceptron

## RÃ©pondre aux questions suivantes:

1. Quâ€™est ce quâ€™un Perceptron ? Quel est le lien entre un neurone biologique et un perceptron ?   

Un perceptron est un modÃ¨le de neurone artificiel, basÃ© sur le neurone biologique, qui peut Ãªtre utilisÃ© pour effectuer des tÃ¢ches de classification binaire. 

Le neurone biologique reÃ§oit des signaux Ã©lectriques de plusieurs autres neurones Ã  travers les dendrites. Ces signaux sont pondÃ©rÃ©s par des synapses et sommÃ©s dans le corps cellulaire du neurone. Si la somme dÃ©passe un certain seuil, le neurone envoie un signal Ã©lectrique le long de l'axone.

Un perceptron prend plusieurs entrÃ©es, applique des poids aux entrÃ©es, les somme et passe le rÃ©sultat Ã  travers une fonction d'activation pour produire une sortie. La sortie est 0 ou 1, qui est ensuite utilisÃ©e pour prÃ©dire la classe de l'entrÃ©e. Le perceptron est utilisÃ© dans les rÃ©seaux de neurones pour effectuer des tÃ¢ches de classification binaire.


2. Quelle est la fonction mathÃ©matique du Perceptron et son usage ? DÃ©finissez les termes de lâ€™Ã©quation.   

La fonction mathÃ©matique du perceptron est dÃ©finie comme suit :   

```python
y = f(w1*x1 + w2*x2 + ... + wn*xn)
```

OÃ¹ :
- `y` est la sortie du perceptron,
- `f` est la fonction d'activation,
- `w1, w2, ..., wn` sont les poids associÃ©s aux entrÃ©es `x1, x2, ..., xn`.

La fonction d'activation est gÃ©nÃ©ralement une fonction seuil qui produit une sortie binaire (0 ou 1) en fonction de la somme pondÃ©rÃ©e des entrÃ©es. L'usage du perceptron est de prÃ©dire la classe de l'entrÃ©e en fonction des poids associÃ©s aux entrÃ©es et de la fonction d'activation.

3. Donnez une ou plusieurs rÃ¨gles dâ€™apprentissage du Perceptron.   

Le perceptron est un modÃ¨le d'apprentissage supervisÃ© basÃ© sur un algorithme d'apprentissage simple.
Voici quelques rÃ¨gles fondamentales d'apprentissage du perceptron :   

i. Mise Ã  jour des poids: Si le Perceptron fait une erreur dans sa prÃ©diction pour un exemple donnÃ©e, ses poids w sont mis Ã  jour selon la rÃ¨gle suivante:
```python
w(t+1) = w(t) + Î·(y - y_pred)x
```
OÃ¹:
- `w(t)` est le vecteur de poids Ã  l'itÃ©ration t,
- `Î·` est le taux d'apprentissage (learning rate),
- `y` est la vraie valeur de la classe (valeur cible),
- `y_pred` est la valeur prÃ©dite par le Perceptron,
- `x` est le vecteur d'entrÃ©e.

ii. Condition d'arrÃªt: L'algorithme d'apprentissage du Perceptron s'arrÃªte lorsque tous les exemples d'entraÃ®nement sont classÃ©s correctement ou lorsque le nombre d'itÃ©rations atteint un certain seuil.

iii. Seuil de dÃ©cision: La sortie du Perceptron dÃ©pend de la fonction d'activation. Typiquement :
```python
y_pred = 1 si w*x >= 0
y_pred = 0 sinon
```

4. Le perceptron utilise gÃ©nÃ©ralement une fonction dâ€™activation, laquelle ?   

Le perceptron utilise gÃ©nÃ©ralement une fonction d'activation seuil, Ã©galement appelÃ©e fonction d'activation de Heaviside. La fonction d'activation seuil produit une sortie binaire (0 ou 1) en fonction de la somme pondÃ©rÃ©e des entrÃ©es. La fonction d'activation seuil est dÃ©finie comme suit :
```python
f(x) = 0 si x < 0
f(x) = 1 si x >= 0
```
La fonction d'activation seuil est utilisÃ©e pour introduire une non-linÃ©aritÃ© dans le modÃ¨le de perceptron et pour produire une sortie binaire qui peut Ãªtre utilisÃ©e pour prÃ©dire la classe de l'entrÃ©e.

5. Quel est le processus d'entraÃ®nement du Perceptron ?   

Le processus d'entraÃ®nement se dÃ©roule comme suit :   

i. Initialisation des poids :

Les poids w et le biais ğ‘ sont initialisÃ©s (souvent Ã  zÃ©ro ou Ã  de petites valeurs alÃ©atoires).   

ii. PrÃ©sentation des donnÃ©es :

Chaque exemple de l'ensemble d'entraÃ®nement est prÃ©sentÃ© au Perceptron, un par un.   

iii. Calcul de la sortie :

La sortie y^ est calculÃ©e en appliquant la fonction d'activation Ã  ğ‘¤ â‹… ğ‘¥ + ğ‘ .   

iv. Mise Ã  jour des poids :

Si ğ‘¦^ â‰  ğ‘¦ (lorsquâ€™il y a une erreur), les poids et le biais sont mis Ã  jour selon la rÃ¨gle mentionnÃ©e ci-dessus.   

v. RÃ©pÃ©tition :

L'ensemble des donnÃ©es est parcouru plusieurs fois (Ã©poques) jusqu'Ã  ce que :
Les erreurs soient minimisÃ©es ou,
Le nombre maximal d'itÃ©rations soit atteint.   

vi. Convergence :

Si les donnÃ©es sont linÃ©airement sÃ©parables, le Perceptron converge et trouve une solution. Si elles ne le sont pas, l'algorithme peut ne jamais s'arrÃªter (dans ce cas, des variations comme le Perceptron Ã  marges ou lâ€™utilisation du SVM sont utilisÃ©es).



6. Quelles sont les limites du Perceptron ?   

Les limites du perceptron sont les suivantes :
- Le perceptron ne peut pas apprendre des fonctions non linÃ©aires, car il utilise une fonction d'activation linÃ©aire.
- Le perceptron est limitÃ© Ã  la classification binaire, car il produit une sortie binaire (0 ou 1).
- Le perceptron peut Ãªtre sensible aux valeurs aberrantes dans les donnÃ©es d'entraÃ®nement, ce qui peut affecter sa capacitÃ© Ã  gÃ©nÃ©raliser.
- Le perceptron peut nÃ©cessiter un grand nombre d'itÃ©rations pour converger vers une solution optimale, en particulier pour des problÃ¨mes complexes.
- Le perceptron peut Ãªtre sensible au choix des hyperparamÃ¨tres, tels que le taux d'apprentissage et le nombre d'itÃ©rations.

7. Vous dÃ©veloppez votre propre Perceptron Ã  lâ€™aide de Python en
programmation orientÃ©e objet. Vous le testez sur des donnÃ©es factices
gÃ©nÃ©rÃ©es de maniÃ¨re alÃ©atoire.   
